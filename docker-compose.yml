services:
  opensearch:
    image: opensearchproject/opensearch:latest
    container_name: opensearch
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD:-StrongPassword123!}
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - rag-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    environment:
      # Reduce noisy per-request access logs from actix_web middleware logger.
      - RUST_LOG=warn,actix_web=warn
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - rag-network
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-lc",
          "exec 3<>/dev/tcp/localhost/6333; printf 'GET /healthz HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3; head -n 1 <&3 | grep -q '200'"
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    command:
      - "postgres"
      - "-c"
      - "max_connections=300"
      - "-c"
      - "shared_buffers=512MB"
      - "-c"
      - "work_mem=8MB"
      - "-c"
      - "maintenance_work_mem=256MB"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=document_storage
    ports:
      - "127.0.0.1:5433:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - rag-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  pgbouncer:
    image: edoburu/pgbouncer:latest
    container_name: pgbouncer
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=postgres
      - DB_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - DB_NAME=document_storage
      - AUTH_TYPE=scram-sha-256
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=1000
      - DEFAULT_POOL_SIZE=50
      - MIN_POOL_SIZE=10
      - RESERVE_POOL_SIZE=20
      - SERVER_IDLE_TIMEOUT=300
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag-network

  # RustFS (S3-compatible object storage for document-storage)
  rustfs:
    image: rustfs/rustfs:latest
    container_name: rustfs-server
    security_opt:
      - "no-new-privileges:true"
    ports:
      - "9000:9000" # S3 API port
      - "9001:9001" # Console port
    environment:
      - RUSTFS_VOLUMES=/data/rustfs{0...3}
      - RUSTFS_ADDRESS=0.0.0.0:9000
      - RUSTFS_CONSOLE_ADDRESS=0.0.0.0:9001
      - RUSTFS_CONSOLE_ENABLE=true
      - RUSTFS_EXTERNAL_ADDRESS=:9000
      - RUSTFS_CORS_ALLOWED_ORIGINS=*
      - RUSTFS_CONSOLE_CORS_ALLOWED_ORIGINS=*
      - RUSTFS_ACCESS_KEY=${RUSTFS_ACCESS_KEY:-rustfsadmin}
      - RUSTFS_SECRET_KEY=${RUSTFS_SECRET_KEY:-rustfsadmin}
      - RUSTFS_OBS_LOGGER_LEVEL=info
      - RUSTFS_TLS_PATH=/opt/tls
      # Object Cache
      - RUSTFS_OBJECT_CACHE_ENABLE=true
      - RUSTFS_OBJECT_CACHE_TTL_SECS=300
    volumes:
      - rustfs_data_0:/data/rustfs0
      - rustfs_data_1:/data/rustfs1
      - rustfs_data_2:/data/rustfs2
      - rustfs_data_3:/data/rustfs3
      - rustfs_logs:/app/logs
    networks:
      - rag-network
      - rustfs-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:9000/health && curl -f http://localhost:9001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    # Enable built-in Prometheus metrics plugin (exposes :15692/metrics)
    command: >
      sh -c "
        rabbitmq-plugins enable --offline rabbitmq_prometheus &&
        rabbitmq-server
      "
    ports:
      - "5672:5672"
      - "15672:15672"
      - "15692:15692"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER:-guest}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS:-guest}
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - rag-network
    healthcheck:
      test: ["CMD-SHELL", "rabbitmq-diagnostics -q ping"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  infinity-embed:
    image: michaelf34/infinity:latest
    container_name: infinity-embed
    # Stronger multilingual embedding model (better recall for RU factoid QA).
    # NOTE: this changes vector dimensionality -> requires re-indexing into a new Qdrant collection.
    command: ["v2", "--model-id", "BAAI/bge-m3", "--port", "7997"]
    environment:
      # Make the container see NVIDIA GPUs (requires NVIDIA Container Toolkit on host).
      # Pin embeddings service to GPU id 0.
      - NVIDIA_VISIBLE_DEVICES=4
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    networks:
      - rag-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids:
                - "2,4"
              capabilities:
                - gpu

  # Stateless Hybrid Retrieval microservice (scale this one for multiple replicas)
  retrieval:
    build:
      context: ./service
    #ports:
    #  - "8080:8080"
    environment:
      # =========================
      # Retrieval / Search quality knobs (RAG_*)
      # =========================
      # Service identity
      - RAG_SERVICE_NAME=hybrid-retrieval
      - RAG_ENVIRONMENT=dev
      - RAG_LOG_LEVEL=INFO
      # OpenSearch (BM25)
      - RAG_OS_URL=http://opensearch:9200
      # Optional auth:
      # - RAG_OS_USERNAME=...
      # - RAG_OS_PASSWORD=...
      - RAG_OS_INDEX_ALIAS=rag_chunks
      - RAG_OS_INDEX_PREFIX=rag_chunks_v
      # Qdrant (Vector)
      - RAG_QDRANT_URL=http://qdrant:6333
      # Optional auth:
      # - RAG_QDRANT_API_KEY=...
      # Use a separate collection because the host Infinity embedding model is 512-dim
      # (existing 'rag_chunks' may already be created with a different vector size).
      # BAAI/bge-m3 is 1024-dim -> use a separate collection to avoid dimension mismatch.
      - RAG_QDRANT_COLLECTION=rag_chunks_bge_m3_1024
      - RAG_VECTOR_DISTANCE=cosine
      # Embeddings (Infinity inside docker network)
      - RAG_EMBEDDING_PROVIDER=http
      - RAG_EMBEDDING_URL=http://infinity-embed:7997/embeddings
      - RAG_EMBEDDING_MODEL=BAAI/bge-m3
      # Optional auth (if your embeddings endpoint needs it):
      # - RAG_EMBEDDING_API_KEY=...
      - RAG_EMBEDDING_TIMEOUT_S=10
      - RAG_EMBEDDING_BATCH_SIZE=4048
      - RAG_EMBEDDING_CONCURRENCY=32
      - RAG_VECTOR_SIZE=1024
      # Contextual Chunk Headers (CCH) for embeddings (opt-in; requires re-index/re-embed when enabled)
      - RAG_EMBEDDING_CONTEXTUAL_HEADERS_ENABLED=true
      - RAG_EMBEDDING_CONTEXTUAL_HEADERS_MAX_CHARS=400
      # Chunking (used only for mode=document indexing)
      - RAG_CHUNK_MAX_TOKENS=300
      - RAG_CHUNK_OVERLAP_TOKENS=50
      # Candidate pool (QUALITY): increase recall before fusion/rerank
      - RAG_DEFAULT_TOP_K=20
      - RAG_BM25_TOP_K=200
      - RAG_VECTOR_TOP_K=200
      # Fusion tuning
      - RAG_RRF_K=60
      - RAG_WEIGHT_BM25=1.0
      - RAG_WEIGHT_VECTOR=1.0
      - RAG_FUSION_ALPHA=0.75
      # IMPORTANT for file_hit@k: return more unique doc_ids in top_k by limiting chunks-per-doc.
      - RAG_MAX_CHUNKS_PER_DOC=1
      # Sources / URI redaction
      - RAG_REDACT_URI_MODE=none
      # Rerank (Infinity rerank service started by this compose)
      - RAG_RERANK_MODE=auto
      - RAG_RERANK_URL=http://infinity-rerank:7998/rerank
      - RAG_RERANK_MODEL=BAAI/bge-reranker-v2-m3
      # Optional auth (if your rerank endpoint needs it):
      # - RAG_RERANK_API_KEY=...
      # Rerank knobs (QUALITY): increase re-ranked candidate cap + allow more time
      - RAG_RERANK_TIMEOUT_S=15
      - RAG_RERANK_MAX_CANDIDATES=200
      - RAG_RERANK_AUTO_MIN_QUERY_TOKENS=6
      - RAG_RERANK_AUTO_MIN_INTERSECTION=2
      # Page-level improvements (QUALITY)
      - RAG_ENABLE_PAGE_DEDUPLICATION=true
      - RAG_ENABLE_PARENT_PAGE_RETRIEVAL=true
      # Observability (optional)
      - RAG_OTEL_ENABLED=false
      - RAG_OTEL_SERVICE_NAME=hybrid-retrieval
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      opensearch:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      infinity-embed:
        condition: service_started
      infinity-rerank:
        condition: service_started
    networks:
      - rag-network

  # Document Storage Service
  document-storage:
    build:
      context: ./document-storage
    ports:
      - "8081:8081"
    environment:
      # =========================
      # Document storage (STORAGE_*)
      # =========================
      - STORAGE_SERVICE_NAME=document-storage
      - STORAGE_ENVIRONMENT=dev
      - STORAGE_LOG_LEVEL=INFO
      - STORAGE_STORAGE_BACKEND=s3
      - STORAGE_STORAGE_PATH=/data/documents
      - STORAGE_S3_ENDPOINT=http://rustfs:9000
      - STORAGE_S3_BUCKET=${STORAGE_S3_BUCKET:-documents}
      - STORAGE_S3_ACCESS_KEY=${RUSTFS_ACCESS_KEY:-rustfsadmin}
      - STORAGE_S3_SECRET_KEY=${RUSTFS_SECRET_KEY:-rustfsadmin}
      - STORAGE_S3_REGION=${STORAGE_S3_REGION:-us-east-1}
      - STORAGE_DB_URL=postgresql://postgres:${POSTGRES_PASSWORD:-postgres}@pgbouncer:5432/document_storage
      - STORAGE_MAX_FILE_SIZE_MB=100
      # Allow-list for uploaded file types (keep aligned with doc-processor capabilities)
      - STORAGE_ALLOWED_CONTENT_TYPES=text/plain,text/markdown,application/pdf,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/vnd.openxmlformats-officedocument.presentationml.presentation,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,text/html,application/xhtml+xml,text/xml,application/xml
    volumes:
      - document-storage-data:/data/documents
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_started
      rustfs:
        condition: service_healthy
    networks:
      - rag-network
      - rustfs-network

  # vLLM (OpenAI-compatible) hosting Granite-Docling VLM for document-to-text extraction.
  # NOTE: requires NVIDIA GPU + drivers on the host.
  vllm-docling:
    image: vllm/vllm-openai:latest
    container_name: vllm-docling
    command: ["--model", "ibm-granite/granite-docling-258M", "--port", "8123"]
    ports:
      - "8123:8123"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    networks:
      - rag-network
    #If your Docker supports it, uncomment GPU settings below:
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # Document Processor Service (pulls files from document-storage, uses Granite-Docling via vLLM, indexes into retrieval)
  doc-processor:
    build:
      context: ./doc-processor
    # ports:
    #   - "8082:8082"
    environment:
      # =========================
      # Document processing (PROCESSOR_*)
      # =========================
      - PROCESSOR_SERVICE_NAME=doc-processor
      - PROCESSOR_ENVIRONMENT=dev
      - PROCESSOR_LOG_LEVEL=INFO
      - PROCESSOR_STORAGE_URL=http://document-storage:8081
      - PROCESSOR_STORAGE_TIMEOUT_S=60
      - PROCESSOR_RETRIEVAL_URL=http://retrieval:8080
      - PROCESSOR_RETRIEVAL_TIMEOUT_S=60
      - PROCESSOR_VLM_BASE_URL=http://vllm-docling:8123/v1
      # Optional auth (if your VLM endpoint needs it):
      # - PROCESSOR_VLM_API_KEY=...
      - PROCESSOR_VLM_MODEL=ibm-granite/granite-docling-258M
      # Extraction quality knobs (QUALITY)
      - PROCESSOR_VLM_TIMEOUT_S=180
      - PROCESSOR_MAX_PAGES=35
      - PROCESSOR_MAX_IMAGE_SIDE_PX=2000
      # Chunking knobs
      - PROCESSOR_CHUNK_SIZE_CHARS=4000
      - PROCESSOR_CHUNK_OVERLAP_CHARS=300
    depends_on:
      document-storage:
        condition: service_started
      retrieval:
        condition: service_started
      vllm-docling:
        condition: service_started
    networks:
      - rag-network

  ingestion-worker:
    build:
      context: ./doc-processor
    command: ["python", "-m", "app.worker"]
    environment:
      - WORKER_RABBIT_URL=amqp://${RABBITMQ_DEFAULT_USER:-guest}:${RABBITMQ_DEFAULT_PASS:-guest}@rabbitmq:5672/
      - WORKER_QUEUE=ingestion.tasks
      - WORKER_RETRY_QUEUE=ingestion.tasks.retry
      - WORKER_DLQ_QUEUE=ingestion.tasks.dlq
      - WORKER_RETRY_TTL_MS=5000
      - WORKER_MAX_ATTEMPTS=5
      - WORKER_PREFETCH=5
      - WORKER_METRICS_PORT=8083
      - WORKER_STORAGE_URL=http://document-storage:8081
      - WORKER_STORAGE_TIMEOUT_S=60
      - WORKER_RETRIEVAL_URL=http://retrieval:8080
      - WORKER_RETRIEVAL_TIMEOUT_S=60
      - WORKER_DOC_PROCESSOR_URL=http://doc-processor:8082
      - WORKER_DOC_PROCESSOR_TIMEOUT_S=300
      - WORKER_LOG_LEVEL=INFO
    depends_on:
      rabbitmq:
        condition: service_healthy
      document-storage:
        condition: service_started
      retrieval:
        condition: service_started
      doc-processor:
        condition: service_started
    networks:
      - rag-network

  # RAG LLM gate (calls retrieval + LLM)
  rag-gate:
    build:
      context: ./gate
    ports:
      - "8090:8090"
    environment:
      # =========================
      # Gate / RAG orchestration (GATE_*)
      # =========================
      - GATE_SERVICE_NAME=rag-gate
      - GATE_ENVIRONMENT=dev
      - GATE_LOG_LEVEL=INFO
      # Use docker network service name for retrieval (no public port required)
      - GATE_RETRIEVAL_URL=http://retrieval:8080
      - GATE_RETRIEVAL_TIMEOUT_S=60
      - GATE_RETRIEVAL_MODE=hybrid
      # Default top_k for chat requests (ru_eval overrides per-request, but keeping this aligned helps).
      - GATE_TOP_K=8
      - GATE_MAX_CONTEXT_CHARS=18000
      # Context packing (segment stitching) (opt-in)
      - GATE_SEGMENT_STITCHING_ENABLED=false
      - GATE_SEGMENT_STITCHING_MAX_CHUNKS=4
      - GATE_SEGMENT_STITCHING_GROUP_BY_PAGE=true
      # Multi-query retrieval (RRF fusion of query variants)
      - GATE_MULTI_QUERY_ENABLED=true
      - GATE_MULTI_QUERY_MAX_QUERIES=4
      - GATE_MULTI_QUERY_TOP_K_MULTIPLIER=12
      - GATE_MULTI_QUERY_RRF_K=60
      # Two-pass retrieval (second query augmented with hint terms from pass1 hits)
      - GATE_TWO_PASS_ENABLED=false
      - GATE_TWO_PASS_HINT_MAX_TERMS=8
      - GATE_TWO_PASS_MIN_UNIQUE_DOCS=3
      # BM25 anchor pass: ensure exact-match entities don't get dropped by hybrid/rerank
      - GATE_BM25_ANCHOR_ENABLED=true
      - GATE_BM25_ANCHOR_TOP_K=60
      - GATE_BM25_ANCHOR_RRF_K=60
      # Document Storage
      - GATE_STORAGE_URL=http://document-storage:8081
      - GATE_STORAGE_TIMEOUT_S=60
      # Document Processor
      - GATE_DOC_PROCESSOR_URL=http://doc-processor:8082
      - GATE_DOC_PROCESSOR_TIMEOUT_S=300
      # Async ingestion queue
      - GATE_RABBIT_URL=amqp://${RABBITMQ_DEFAULT_USER:-guest}:${RABBITMQ_DEFAULT_PASS:-guest}@rabbitmq:5672/
      - GATE_RABBIT_QUEUE=ingestion.tasks
      # LLM (OpenAI-compatible). Keep mock as default to avoid requiring a key by default.
      - GATE_LLM_PROVIDER=${GATE_LLM_PROVIDER:-openai_compat}
      - GATE_LLM_BASE_URL=${GATE_LLM_BASE_URL:-https://inference.asicloud.cudos.org/v1}
      - GATE_LLM_MODEL=${GATE_LLM_MODEL:-openai/gpt-oss-120bt}
      - GATE_LLM_API_KEY=${GATE_LLM_API_KEY:-}
      - GATE_LLM_TIMEOUT_S=60
      # CORS / UI
      - GATE_CORS_ALLOW_ORIGINS=*
    depends_on:
      retrieval:
        condition: service_started
      document-storage:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - rag-network

  # Agentic search service (agent_cli as a microservice)
  agent-search:
    build:
      context: ./agent-search
    ports:
      - "8091:8091"
    environment:
      - AGENT_GATE_URL=http://rag-gate:8090
      - AGENT_GATE_TIMEOUT_S=60
      - AGENT_LLM_BASE_URL=${GATE_LLM_BASE_URL:-https://inference.asicloud.cudos.org/v1}
      - AGENT_LLM_MODEL=${GATE_LLM_MODEL:-openai/gpt-oss-120bt}
      - AGENT_LLM_API_KEY=${GATE_LLM_API_KEY:-}
      - AGENT_LLM_TIMEOUT_S=60
    depends_on:
      rag-gate:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - rag-network

  # Deep research service (langgraph + gate MCP)
  deep-research:
    build:
      context: ./deep-research
    ports:
      - "8092:8092"
    environment:
      - DEEP_LLM_PROVIDER=${GATE_LLM_PROVIDER:-mock}
      - DEEP_LLM_BASE_URL=${GATE_LLM_BASE_URL:-https://inference.asicloud.cudos.org/v1}
      - DEEP_LLM_API_KEY=${GATE_LLM_API_KEY:-}
      - DEEP_LLM_MODEL=${GATE_LLM_MODEL:-meta-llama/llama-3.3-70b-instruct}
      - DEEP_GATE_URL=http://rag-gate:8090
      - DEEP_GATE_TIMEOUT_S=60
      - DEEP_LLM_TEMPERATURE=0
      - DEEP_MAX_ITERATIONS=2
      - DEEP_RETRIEVAL_MODE=hybrid
      - DEEP_TOP_K=8
      - DEEP_RERANK=true
    depends_on:
      rag-gate:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - rag-network

  # Simple frontend (nginx static + proxy /api to rag-gate)
  ui:
    build:
      context: ./ui
    ports:
      - "3300:80"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      rag-gate:
        condition: service_started
    networks:
      - rag-network

  # Rerank service (Infinity). Kept in the same docker network for stable DNS (infinity-rerank).
  infinity-rerank:
    image: michaelf34/infinity:latest
    container_name: infinity-rerank
    command: ["v2", "--model-id", "BAAI/bge-reranker-v2-m3", "--port", "7998"]
    environment:
      # Make the container see NVIDIA GPUs (requires NVIDIA Container Toolkit on host).
      # Pin embeddings service to GPU id 0.
      - NVIDIA_VISIBLE_DEVICES=4
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    networks:
      - rag-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids:
                - "4"
              capabilities:
                - gpu
  prometheus:
    image: prom/prometheus:v2.55.0
    container_name: prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - rag-network

  # Postgres metrics exporter (Prometheus)
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.16.0
    container_name: postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://postgres:${POSTGRES_PASSWORD:-postgres}@postgres:5432/postgres?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag-network

  # OpenSearch metrics exporter (Prometheus)
  opensearch-exporter:
    image: prometheuscommunity/elasticsearch-exporter:v1.8.0
    container_name: opensearch-exporter
    command:
      - "--es.uri=http://opensearch:9200"
      - "--es.all"
      - "--es.indices"
      - "--es.shards"
      - "--es.cluster_settings"
      - "--es.timeout=10s"
    depends_on:
      opensearch:
        condition: service_healthy
    networks:
      - rag-network

  # Host metrics (Prometheus)
  node-exporter:
    image: prom/node-exporter:v1.8.2
    container_name: node-exporter
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--path.rootfs=/rootfs"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - rag-network

  # Container metrics (Prometheus)
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - rag-network

  grafana:
    image: grafana/grafana:11.3.1
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - rag-network

volumes:
  opensearch-data:
    driver: local
  qdrant-data:
    driver: local
  postgres-data:
    driver: local
  document-storage-data:
    driver: local
  rustfs_data_0:
    driver: local
  rustfs_data_1:
    driver: local
  rustfs_data_2:
    driver: local
  rustfs_data_3:
    driver: local
  rustfs_logs:
  rabbitmq-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

networks:
  rag-network:
    driver: bridge
  rustfs-network:
    driver: bridge
